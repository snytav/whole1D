# -*- coding: utf-8 -*-
"""multiple_out

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YF_pbxgRJ91cOKG0japQnjABsux3wNvf
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# git clone https://github.com/snytav/whole1D

# Commented out IPython magic to ensure Python compatibility.
# %cd whole1D

import torch
import torch.nn as nn
from torch.autograd.functional import jacobian,hessian
from deriv_example import neural_network_x,neural_network,nx
from deriv_example import W,x_space,pn,sigmoid
import autograd.numpy as np

xt = torch.from_numpy(x_space)

class Multiply(nn.Module):
    def __init__(self, N,M):
        super().__init__()
        self.N = N
        self.M = M
        self.weight = torch.nn.Parameter(torch.rand(self.N,self.M))

    def set_weight(self,w):
        wn = w.repeat(self.M,1)
        self.weight = nn.Parameter(wn.T)
        return

    def forward(self, x):

        x = torch.multiply(self.weight,x).T
        return x

ml = Multiply(nx,nx)

ml.weight = nn.Parameter(torch.from_numpy(W[0]))

y1_n_2 = np.dot(x_space[2],W[0])

y1_t_2 = ml(xt[2])

d_y1_2 = np.abs(y1_n_2 - y1_t_2.T.detach().numpy())
d_y1_2

y1_n = [np.dot(xi,W[0])[0] for xi in x_space]
y1_n = np.array(y1_n)
y1_n

w = torch.from_numpy(W[0])
w3=torch.cat((w,w,w))

ml.set_weight(w)       #weight = nn.Parameter(w3.T)
ml.weight

ml.weight,xt

torch.multiply(ml.weight,xt).T

y1_t = ml(xt)
y1_t



y1_n.shape,y1_t.shape

#d_y1  = np.abs
print(y1_n,y1_t.detach().numpy())

d_y1 = np.abs(y1_n-y1_t.detach().numpy())
d_y1

w1 = torch.from_numpy(W[1])

y1_n_2,sigmoid(y1_n_2),W[1]

y1_t_2,torch.sigmoid(y1_t_2),w1

y2_n_2 = np.dot(sigmoid(y1_n_2),W[1])
y2_n_2

y2_t_2 = torch.inner(torch.sigmoid(y1_t_2),w1)
y2_t_2

# d_y2_2 = np.abs(y2_n_2 - y2_t_2.detach().numpy())
# d_y2_2



w1 = torch.from_numpy(W[1])

y1_t[0,:],w1.T

#y2_t_2 = torch.inner(y1_t[0,:],w1.reshape(3))
y2_t_2

y2_t_2

# 2nd layer input
layer2_input = np.array([sigmoid(yi) for yi in y1_n])
layer2_input

layer2_input_torch = torch.sigmoid(y1_t)#torch.matmul(y1_t,w1)
layer2_input_torch

d_layer2_input = np.abs(layer2_input - layer2_input_torch.detach().numpy())
d_layer2_input

w1.shape
fc = nn.Linear(1,3)
fc.weight = nn.Parameter(w1.T)
fc.bias = nn.Parameter(torch.zeros(fc.bias.shape).double())
fc.weight.dtype

class MultipleOutLinear(nn.Module):
    def __init__(self, N):
        super().__init__()
        self.N = N

        self.weight = torch.nn.Parameter(torch.rand(self.N,1))

    def forward(self, x):

        x = torch.matmul(x,self.weight)
        return x

fc = MultipleOutLinear(3)
fc.weight = nn.Parameter(w1)

# layer 2 output
out_layer2 = np.array([np.dot(xi,W[1]) for xi in layer2_input])
out_layer2

out_layer2_t = torch.matmul(layer2_input_torch,w1)
out_layer2_t

layer2_input_torch.shape,w1.shape,fc.weight.shape

fc.weight.dtype,layer2_input_torch.dtype

out_layer2_t = fc(layer2_input_torch)



d_out_layer2 = np.abs(out_layer2 - out_layer2_t.detach().numpy())
d_out_layer2

net_out_s = []
for xi in x_space:
    net_out = neural_network(W, xi)[0][0]
    net_out_s.append(net_out)
net_out_s = np.array(net_out_s)

class WholePoisNet(nn.Module):
    def __init__(self,nx):
        super(WholePoisNet,self).__init__()
        self.nx = nx
        fc1 = Multiply(1,self.nx)
        self.fc1 = fc1
        fc2 = MultipleOutLinear(self.nx)
        self.fc2 = fc2
    def forward(self,x): # at first place replace forward with exact solution
        #return torch.sin(x)
                         # to check loss function
        x = self.fc1(x)
        x = torch.sigmoid(x)
        x = self.fc2(x)
        return x






#x = wh.fc2(x)

#x = torch.sigmoid(x)








if __name__ == "__main__":

    yn = neural_network(W, x_space[2])[0][0]
    wh = WholePoisNet(nx)
    wh.fc1.set_weight(w)   #weight = nn.Parameter(w3.T)
    wh.fc2.weight = nn.Parameter(w1)
    yt = wh(xt[2])
    d_final = np.abs(yn - yt.detach().numpy())
    d1 = np.max(d_final)
    qq = 0